{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhYsISa3t6NC"
      },
      "source": [
        "Getting data from Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IIigjcEtqm7",
        "outputId": "76cc319c-5d1f-4232-d263-ce2baee82e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.50-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.55.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
            "Downloading roboflow-1.1.50-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, idna, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 roboflow-1.1.50\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Computer_Vision-1 to yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251645/251645 [00:04<00:00, 51541.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Computer_Vision-1 in yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9418/9418 [00:05<00:00, 1790.11it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"oSq21nk6YA7JS80deVrH\")\n",
        "project = rf.workspace(\"project-hv5yx\").project(\"computer_vision-5nx0j\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8-obb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9085PtEuXPj"
      },
      "source": [
        "Convert all classes to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0T2mRFruBWF",
        "outputId": "e4e60646-8508-489d-b1a3-16a3f8427eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First number (class IDs) updated to 0 and saved to: Computer_Vision-1/test/labels\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def update_first_number_to_zero(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Updates only the first number (class ID) in each line of YOLO label files to 0.\n",
        "\n",
        "    Parameters:\n",
        "        input_folder (str): Path to folder containing YOLO label files.\n",
        "        output_folder (str): Path to save updated label files.\n",
        "    \"\"\"\n",
        "    # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Loop through each file in the input folder\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        if file_name.endswith(\".txt\"):  # Process only .txt files\n",
        "            input_path = os.path.join(input_folder, file_name)\n",
        "            output_path = os.path.join(output_folder, file_name)\n",
        "\n",
        "            with open(input_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
        "                for line in infile:\n",
        "                    parts = line.strip().split()  # Split line into components\n",
        "                    if len(parts) > 0:\n",
        "                        parts[0] = '0'  # Change the first number (class ID) to 0\n",
        "                        new_line = \" \".join(parts)  # Reassemble the line\n",
        "                        outfile.write(new_line + \"\\n\")  # Write updated line to output file\n",
        "\n",
        "    print(\"First number (class IDs) updated to 0 and saved to:\", output_folder)\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"Computer_Vision-1/test/labelss\"  # Replace with your input folder path\n",
        "output_folder = \"Computer_Vision-1/test/labels\"  # Replace with your output folder path\n",
        "update_first_number_to_zero(input_folder, output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGxCLSYjuj8k"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pcVZE09AueUp",
        "outputId": "2ca6c859-aa7d-4fcd-d76b-0be1a0732fc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.50 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=Computer_Vision-1/data.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=yolov8_training2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_training2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 20.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_training2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 97.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Computer_Vision-1/train/labels... 4116 images, 9 backgrounds, 17 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4116/4116 [00:03<00:00, 1330.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f12_kn_g3_8_jpg.rf.04a438b9f579f07f60f7dd4b3481d112.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0003      1.0316]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f12_kn_g3_8_jpg.rf.e61978f1b7d4584d8127a9c02b0a3a00.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0212]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f13_kn_g3_7_jpg.rf.07ec0f358241c09a08e8ac9c50fefb8f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0684]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f13_kn_g3_7_jpg.rf.d470fc80c15e20b54f9250799d988d73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.082]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f14_kn_g3_2_jpg.rf.30b40e101e45d37fa09f2cee6db3933e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0756]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f14_kn_g3_2_jpg.rf.60edcb2de284a3135c60fa9d9d48e3c1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0526]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f17_kl_g3_20_jpg.rf.16e39bb6e3060e1f44e77f252d843aac.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0158]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f17_kl_g3_20_jpg.rf.5c5b7daea201fa60865bdc86c1caca5c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0768]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f19_sr_g3_12_jpeg.rf.838088c42b9bbf2511918540ae7fbec4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0149]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f1_kn_g3_11_jpg.rf.d52a43b360563d0e68516fa174cf3f6c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0039]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f1_kn_g3_11_jpg.rf.fb06d6dc0b5258c02f3527cfb4e95cac.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0043]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f2_kl_g3_10_jpg.rf.3d52850d7ab86aa9d9e8c49280303f7e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0244]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f2_kl_g3_10_jpg.rf.61d5934c3a5a8e5c1dece5952e48760c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0585]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f4_kl_g3_19_jpg.rf.c1f7708089a3f676f9d212adeed36453.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0141]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f5_kl_g3_7_jpg.rf.64c788fcd4bbd8860f8da576e07fe365.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0099]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f5_kl_g3_7_jpg.rf.797940cc402ab672b08b530463a2fc39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/train/images/f9_kl_g3_17_jpg.rf.360a7fd9d12c879b7f37cc02ebdcea5a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0074]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Computer_Vision-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Computer_Vision-1/valid/labels... 391 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:00<00:00, 844.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/Computer_Vision-1/valid/images/f5_kn_g3_3_jpg.rf.ed600f13893cd485ce07b10f71cf8cdf.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0294]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Computer_Vision-1/valid/labels.cache\n",
            "Plotting labels to runs/detect/yolov8_training2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8_training2\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/25      2.27G       1.79      2.106      1.587          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:33<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.524      0.431      0.438      0.224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/25      2.21G      1.753      1.729      1.563         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:32<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.632      0.548      0.567      0.295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/25      2.22G      1.746      1.626      1.559         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:28<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.701      0.581      0.635      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/25      2.29G       1.74      1.579      1.555         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:28<00:00,  2.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  2.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.732      0.622      0.699      0.393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/25      2.23G      1.666      1.484      1.511         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:30<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.754      0.634        0.7      0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/25      2.22G      1.645      1.438      1.489         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:28<00:00,  2.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.729      0.634      0.689      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/25      2.31G      1.616      1.383      1.467         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:29<00:00,  2.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.773      0.662      0.736      0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/25      2.29G      1.588      1.347      1.448         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:31<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.801      0.683      0.763      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/25      2.29G      1.567      1.291      1.436         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:29<00:00,  2.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.786      0.688      0.753      0.464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/25      2.21G      1.554      1.279      1.433         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:28<00:00,  2.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.804      0.694      0.775      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/25      2.19G       1.55      1.249      1.421         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:30<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.857      0.694      0.786      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/25       2.2G      1.519       1.24      1.408          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:33<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.834      0.683      0.788      0.483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/25      2.21G      1.505      1.203      1.397         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:28<00:00,  2.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.816      0.706      0.774      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/25      2.19G      1.487      1.173      1.385         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:33<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022       0.84      0.698      0.798      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/25      2.22G      1.486      1.153      1.381         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:28<00:00,  2.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.832      0.677      0.771      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/25      2.17G      1.394     0.9835      1.331          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:19<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.798      0.702      0.779      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/25      2.19G      1.386     0.9541      1.323          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:23<00:00,  3.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  4.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.862      0.692      0.789      0.492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/25      2.22G      1.353     0.9094      1.303          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:21<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.837      0.717      0.786      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/25      2.27G      1.344     0.8905      1.293          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:18<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.865      0.709      0.798      0.511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/25      2.18G      1.321     0.8574      1.277         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:18<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.846      0.721      0.797      0.512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/25      2.17G      1.304     0.8419      1.264          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:23<00:00,  3.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.841      0.734      0.797      0.506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/25      2.21G      1.282     0.8099      1.249          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:18<00:00,  3.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.879       0.73      0.808      0.519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/25      2.17G      1.264     0.7893      1.239          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:18<00:00,  3.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.855      0.741      0.809      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/25      2.16G      1.252     0.7701      1.235         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:21<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.858      0.746      0.806      0.531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/25      2.21G      1.244     0.7538      1.221          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 257/257 [01:20<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.875      0.738      0.807      0.529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "25 epochs completed in 0.636 hours.\n",
            "Optimizer stripped from runs/detect/yolov8_training2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/yolov8_training2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/yolov8_training2/weights/best.pt...\n",
            "Ultralytics 8.3.50 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        390       1022      0.856      0.746      0.807      0.532\n",
            "Speed: 0.3ms preprocess, 2.5ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_training2\u001b[0m\n",
            "Ultralytics 8.3.50 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Computer_Vision-1/test/labels... 196 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:00<00:00, 1704.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Computer_Vision-1/test/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        196        489      0.884      0.729      0.814      0.513\n",
            "Speed: 0.4ms preprocess, 5.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_training22\u001b[0m\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'DetMetrics' object has no attribute 'get'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP) of an\n    object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (dict of str): A dict of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n        names (dict of str): A dict of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b81360046c31>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Step 4: Print evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N/A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N/A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmap50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'map50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N/A'\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# mAP at IoU=0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;34m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DetMetrics' object has no attribute 'get'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP) of an\n    object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (dict of str): A dict of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n        names (dict of str): A dict of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    "
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 1: Load the YOLOv8 model (choose the appropriate model size)\n",
        "model = YOLO('yolov8n.pt')  # 'yolov8n.pt' is the nano model, adjust for 's', 'm', 'l' etc.\n",
        "\n",
        "# Step 2: Train the model\n",
        "results = model.train(\n",
        "    data='Computer_Vision-1/data.yaml',  # Updated path to data.yaml\n",
        "    epochs=25,              # Number of epochs for training\n",
        "    imgsz=640,              # Image size (default is 640x640)\n",
        "    batch=16,               # Batch size (adjust for your GPU memory)\n",
        "    device=0,               # Use GPU (set to -1 for CPU, 0 for the first GPU)\n",
        "    workers=4,              # Number of workers for faster data loading\n",
        "    name='yolov8_training'  # Name for the training session\n",
        ")\n",
        "\n",
        "# Step 3: Evaluate the model on the test set with IoU threshold\n",
        "iou_threshold = 0.5  # Set IoU threshold (default for precision/recall is 0.5)\n",
        "metrics = model.val(\n",
        "    data='Computer_Vision-1/data.yaml',  # Path to data.yaml\n",
        "    split='test',                        # Specify evaluation on the test split\n",
        "    iou=iou_threshold                    # Include IoU threshold for evaluation\n",
        ")\n",
        "\n",
        "# Step 4: Print evaluation metrics\n",
        "if metrics:\n",
        "    precision = metrics.get('precision', 'N/A')\n",
        "    recall = metrics.get('recall', 'N/A')\n",
        "    map50 = metrics.get('map50', 'N/A')         # mAP at IoU=0.5\n",
        "    map_5095 = metrics.get('map', 'N/A')        # mAP at IoU=0.5:0.95\n",
        "    iou_used = iou_threshold                    # Display IoU threshold used\n",
        "\n",
        "    # Approximated accuracy as the harmonic mean of precision and recall\n",
        "    accuracy = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "\n",
        "    print(f\"Evaluation Metrics (IoU={iou_used}):\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"mAP@0.5: {map50:.4f}\")\n",
        "    print(f\"mAP@0.5:0.95: {map_5095:.4f}\")\n",
        "    print(f\"Accuracy (approximated): {accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"No evaluation metrics available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "l5USpdqUuz7g",
        "outputId": "925d3468-a7fc-4445-b211-969dba6f3af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.50 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Computer_Vision-1/test/labels.cache... 196 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        196        489      0.871      0.734      0.805      0.514\n",
            "Speed: 0.5ms preprocess, 5.0ms inference, 0.1ms loss, 4.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_training23\u001b[0m\n",
            "Model Evaluation Metrics:\n",
            "Precision: 0.5140\n",
            "Recall: 0.5140\n",
            "mAP@0.5 (IoU threshold=0.5): 0.8047\n",
            "mAP@0.5:0.95: 0.5140\n",
            "Average IoU (approx as mAP@0.5): 0.8047\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABblElEQVR4nO3dd3xUVf7/8fedmSSEkBAgkNBDU0ANKG0REFnBqFhYpYiFplhxEQQUFkW/rqCiiOtaoivKKk10dXHjDxdZERQUgURF6aGIFIlAQgmZcs/vD8wkQyaQIJBcfD0fj3k8ks/ccs6cuZN3zty5YxljjAAAAAAHcpV3AwAAAICTRZgFAACAYxFmAQAA4FiEWQAAADgWYRYAAACORZgFAACAYxFmAQAA4FiEWQAAADgWYRYAAACORZgFgArs0UcflWVZ5bb/Sy+9VJdeemm57b+iWbRokSzL0qJFi8q7KQB+RZgFEOLKK69UtWrVtHv37mL35eTkqHbt2urQoYNs29Yvv/yi0aNH69xzz1WlSpVUvXp1paam6j//+U+xdbds2SLLsvTMM8+csA1ffPGF/vSnPykxMVFRUVFKTk7WnXfeqW3btv2mvn3yySfq1q2bEhISFB8fr/bt2+utt94q1brJycmyLCvs7YorrvhN7SpvP/zwgx599FFt2bKlvJsSVBAaLcvS22+/HXaZTp06ybIsnX/++Se1j5kzZ2rq1Km/oZUAKgJPeTcAQMXy0ksv6fzzz9eIESM0c+bMkPvGjRun7OxszZ8/Xxs2bNBll12mPXv2aPDgwWrbtq3279+vGTNm6JprrtGoUaM0efLkMu//hRde0PDhw9W4cWPdd999ql27ttasWaN//OMfmjNnjj766CNdfPHFZd7uvHnz1KtXL3Xs2DE42/nOO+9owIABys7O1ogRI064jdatW+uBBx4oVq9Tp06Z21OR/PDDD3rsscd06aWXKjk5OeS+//73v+XTqF9VqlRJM2fO1C233BJS37Jli5YuXapKlSqd9LZnzpyp1atX6/777y/1Opdccony8vIUGRl50vsFcIoZADjGU089ZSSZjz/+OFhbvny5cblcZsyYMcbr9Zrzzz/fVK5c2Xz55Zch6/r9ftOvXz8jycyePTtY37x5s5FkJk+eXOJ+P//8c+NyuUyXLl3MoUOHQu7buHGjSUxMNLVr1zZ79+4tc5969Ohh6tSpY44cORKs+Xw+06RJE5OSknLC9Rs2bGh69uxZ5v3+VhMmTDCn+6V67ty5RpL59NNPT+t+yuLTTz81ksz1119vPB6P2bNnT8j9TzzxhElMTDSdO3c255133knto2fPnqZhw4alWjYvL88EAoGT2g+A04vTDAAUM3LkSKWkpOiee+7RkSNHFAgEdNddd6lhw4aaMGGC3nvvPa1evVoPPfSQOnToELKu2+1WWlqa4uPj9eijj5Zpv48//rgsy9L06dNVuXLlkPuaNGmip59+Wjt37lRaWpok6ZlnnpFlWdq6dWuxbY0dO1aRkZHat2+fJCk3N1fVqlVTVFRUcBmPx6OEhARFR0eXqZ0lKUt7lixZoj59+qhBgwaKiopS/fr1NWLECOXl5R13HwWna7z55pvF7rMsK+Qx37p1q+655x6de+65io6OVo0aNdSnT5+Q0wnefPNN9enTR5LUrVu34Fv7BeeEhjtn9ueff9Ztt92mxMREVapUSa1atdL06dPDtvOZZ57Rq6++qiZNmigqKkrt2rXT119/fdw+FnXdddcpKipKc+fODanPnDlTffv2ldvtDrve22+/rTZt2ig6OlrVq1fXjTfeqB9//DF4/6WXXqr09HRt3bo12OeCWemCUxxmz56t8ePHq27duqpcubJyc3NLPGf2q6++0lVXXaVq1aopJiZGKSkpev7554P379q1S4MHD1a9evUUFRWl2rVr67rrrqtQp3YATkWYBVCMx+PRq6++qs2bN+vxxx/X3//+d61atUovv/yyKleurA8//FCSNGDAgLDrV61aVdddd53Wrl2rjRs3lmqfhw8f1sKFC9WlSxc1atQo7DL9+vVTVFRU8Jzcvn37Bk8XONY777yjyy+/XNWqVZN0NLx8//33evjhh7Vx40Zt2rRJjz/+uFasWKExY8aUqo0+n0/Z2dnFbgUBtCztmTt3rg4fPqy7775bL7zwglJTU/XCCy+U+JiejK+//lpLly7VjTfeqL/97W+66667tHDhQl166aU6fPiwpKNvm//5z3+WdPQ0krfeektvvfWWWrRoEXabeXl5uvTSS/XWW2/p5ptv1uTJk1W1alUNGjQoJLwVmDlzpiZPnqw777xTf/3rX7VlyxZdf/318vl8pepD5cqVdd1112nWrFnB2jfffKPvv/9eN910U9h1nnjiCQ0YMEDNmjXTlClTdP/992vhwoW65JJLtH//fknSX/7yF7Vu3VoJCQnBPh97/uzjjz+u9PR0jRo1ShMnTizx1IIFCxbokksu0Q8//KDhw4fr2WefVbdu3ULOHb/hhhv0/vvva/DgwXrppZf05z//WQcOHPjN54EDEKcZACjZsGHDTEREhKlSpYrp379/sN66dWtTtWrV4647ZcoUI8nMmzfPGHPi0wwyMzONJDN8+PDjbjclJcVUr149+HvHjh1NmzZtQpZZvny5kWT++c9/BmsHDx40ffv2NZZlGUlGkqlcubL54IMPjru/Ag0bNgyud+xt0qRJZW7P4cOHi+1j0qRJxrIss3Xr1mDt2NMMCh7HN954o9j6ksyECROOu49ly5YVa8vxTjPo2rWr6dq1a/D3qVOnGknm7bffDta8Xq/p2LGjqVKlisnNzQ1pZ40aNUJOC/n3v/9tJJkPP/yw2L6KKjjNYO7cueY///mPsSzLbNu2zRhjzOjRo03jxo2D7St6msGWLVuM2+02TzzxRMj2vvvuO+PxeELqJZ1mULDvxo0bF3sMC+4reKz8fr9p1KiRadiwodm3b1/IsrZtG2OM2bdv3wlPsQFw8piZBVCiJ554QjVq1JDL5dJzzz0XrB84cECxsbHHXbfg/tzc3FLt68CBAyHrHW+7RbfZr18/rVy5Ups2bQrW5syZo6ioKF133XXBWlRUlM455xz17t1bs2bN0ttvv622bdvqlltu0ZdfflmqNnbo0EELFiwoduvfv3+Z21P01IZDhw4pOztbF198sYwxysjIKFV7TqToPnw+n3755Rc1bdpU8fHxWrVq1Ult86OPPlJSUlJInyMiIvTnP/9ZBw8e1GeffRayfL9+/YKz0ZLUpUsXSVJWVlap93n55ZerevXqmj17towxmj17dsj+i/rXv/4l27bVt2/fkNnzpKQkNWvWTJ9++mmp9ztw4MATnoKSkZGhzZs36/7771d8fHzIfQWXVIuOjlZkZKQWLVoUPM0EwKnD1QwAlCguLk7nnnuusrOzlZiYGKzHxsYqOzv7uOuWNpwW3WbR9Y633aLb7NOnj0aOHKk5c+Zo3LhxMsZo7ty5uvLKKxUXFxdcbtiwYfryyy+1atUquVxH/4/v27evzjvvPA0fPlxfffXVCduYkJCg7t27H3eZ0rZn27ZteuSRRzRv3rxiAScnJ+eEbSmNvLw8TZo0SW+88YZ++uknGWN+8z62bt2qZs2aBR/DAgWnJRx7vnCDBg1Cfi8ItmUJdREREerTp49mzpyp9u3b68cffyzxFIMNGzbIGKNmzZqVuK3SKul0l6IK/mk53uXBoqKi9NRTT+mBBx5QYmKi/vCHP+jqq6/WgAEDlJSUVOr2AAiPmVkAZdaiRQvl5OQc93y/b7/9VpLUsmXLUm2zadOm8ng8wfXCyc/P17p160K2WadOHXXp0iV4nuqXX36pbdu2qV+/fsFlvF6vXn/9dfXs2TMkhEVEROjKK6/UihUr5PV6S9XOEylNewKBgHr06KH09HQ9+OCD+uCDD7RgwYLgh7ps2y5x+yV9gUIgEChWu++++/TEE0+ob9++euedd/Tf//5XCxYsUI0aNY67j1OppA9oFQ3WpXHTTTcpMzNTjz76qFq1alXi88q2bVmWpfnz54edRS/48GBpnKoPBkrS/fffr/Xr12vSpEmqVKmSHn74YbVo0eKUzcIDv2fMzAIos6uvvlqzZs3SP//5T40fP77Y/bm5ufr3v/+t5s2bq2nTpqXaZkxMjLp166b//e9/2rp1qxo2bFhsmXfeeUf5+fm6+uqrQ+r9+vXTPffco3Xr1mnOnDmqXLmyrrnmmuD9v/zyi/x+f9jA5/P5ZNt22PtO1ona891332n9+vWaPn16yAe+FixYcMJtF8xsFnyQqUC4Kyi8++67GjhwoJ599tlg7ciRI8XWLcs3jDVs2FDffvutbNsO+cdg7dq1wftPh86dO6tBgwZatGiRnnrqqRKXa9KkiYwxatSokc4555zjbvNUfLNakyZNJEmrV68+4ax9kyZN9MADD+iBBx7Qhg0b1Lp1az377LMlfikEgNJhZhZAmfXu3VstW7bUk08+qRUrVoTcZ9u27r77bu3bt08TJkwo03bHjx8vY4wGDRpU7BJVmzdv1pgxY1S7dm3deeedIffdcMMNcrvdmjVrlubOnaurr75aMTExwftr1aql+Ph4vf/++yEzsAcPHtSHH36o5s2bn9JZuBO1p2C2sujspDEm7NUAjhUXF6eEhAQtXrw4pP7SSy8VW9btdhebAX3hhReKBfeCth0bcsO56qqrtGvXLs2ZMydY8/v9euGFF1SlShV17dr1hNs4GZZl6W9/+5smTJigW2+9tcTlrr/+erndbj322GPF+m6M0S+//BL8PSYm5jef0nHRRRepUaNGmjp1arHHr2D/hw8f1pEjR0Lua9KkiWJjY5Wfn/+b9g+AmVkAJyEyMlLvvvuuLrvsMnXu3DnkG8BmzpypVatW6YEHHtCNN95YbN2FCxcW+8MuSb169dIll1yiZ555Jnid20GDBql27dpau3atXnvtNdm2rY8++ijkA0XS0bDarVs3TZkyRQcOHAh5S186GupGjRql8ePH6w9/+IMGDBigQCCg119/Xdu3by/1zNhPP/0UdtkqVaqoV69epW5P8+bN1aRJE40aNUo//fST4uLi9N5775X6PNLbb79dTz75pG6//Xa1bdtWixcv1vr164std/XVV+utt95S1apV1bJlSy1btkyffPKJatSoEbJc69at5Xa79dRTTyknJ0dRUVH64x//qFq1ahXb5h133KG0tDQNGjRIK1euVHJyst5991198cUXmjp1aqnPkT4Z1113XciH6MJp0qSJ/vrXv2rs2LHasmWLevXqpdjYWG3evFnvv/++7rjjDo0aNUqS1KZNG82ZM0cjR45Uu3btVKVKlZAZ9NJwuVx6+eWXdc0116h169YaPHhw8Dn7/fff6+OPP9b69et12WWXqW/fvmrZsqU8Ho/ef/997d69O+wxAqCMyuEKCgAc5NhLHxX1888/m5EjR5qmTZuaqKgoEx8fb7p37x68HFdRBZdqKun21ltvBZddvHixue6660xCQoKJiIgwDRo0MEOHDjVbtmwpsZ2vvfaakWRiY2NNXl5e2GVmzJhh2rdvb+Lj4010dLTp0KGDeffdd0v1OBzv0lzhLu90ovb88MMPpnv37qZKlSomISHBDB061HzzzTfFLrsV7hvADh8+bG677TZTtWpVExsba/r27Wt+/vnnYpfm2rdvnxk8eLBJSEgwVapUMampqWbt2rWmYcOGZuDAgcXa27hxY+N2u0MuPXXspbmMMWb37t3B7UZGRpoLLrig2KXCjncptmPbGU7RS3MdT0nPz/fee8907tzZxMTEmJiYGNO8eXNz7733mnXr1gWXOXjwoLnppptMfHx8yDgeb9/HXpqrwOeff2569OhhYmNjTUxMjElJSTEvvPCCMcaY7Oxsc++995rmzZubmJgYU7VqVdOhQwfzzjvvHLdvAErHMqaMZ+EDAAAAFQTnzAIAAMCxCLMAAABwLMIsAAAAHKtcw+zixYt1zTXXqE6dOrIsSx988MEJ11m0aJEuuugiRUVFqWnTpsGLjAMAAOD3p1zD7KFDh9SqVSu9+OKLpVp+8+bN6tmzp7p166bMzEzdf//9uv322/Xxxx+f5pYCAACgIqowVzOwLEvvv/9+yLUaj/Xggw8qPT1dq1evDtZuvPFG7d+/X/Pnzz8DrQQAAEBF4qgvTVi2bFmxrwtMTU3V/fffX+I6+fn5Id+wYtu29u7dqxo1apySrzIEAADAqWWM0YEDB1SnTp2Qr84Ox1FhdteuXUpMTAypJSYmKjc3V3l5eWG/jnLSpEl67LHHzlQTAQAAcIr8+OOPqlev3nGXcVSYPRljx47VyJEjg7/n5OSoQYMG2rx5s+Li4iQd/TpCl8sl27Zl23Zw2YJ6IBAI+Y7vkuput1uWZcnv94e0oeB72I/9PvSS6h6PR8aYkLplWXK73cXaWFKdPtEn+kSf6BN9ok/0yal92rdvnxo1alSqr8h2VJhNSkrS7t27Q2q7d+9WXFxc2FlZSYqKilJUVFSxevXq1YNhFgAAABVHwamgpTkl1FHXme3YsaMWLlwYUluwYIE6duxYTi0CAABAeSrXMHvw4EFlZmYqMzNT0tFLb2VmZmrbtm2Sjp4iMGDAgODyd911l7KysjRmzBitXbtWL730kt555x2NGDGiPJoPAACAclauYXbFihW68MILdeGFF0qSRo4cqQsvvFCPPPKIJGnnzp3BYCtJjRo1Unp6uhYsWKBWrVrp2Wef1T/+8Q+lpqaWS/sBAABQvirMdWbPlNzcXFWtWlU5OTmcMwsAAFABlSWvOeqcWQAAAKAowiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHAswiwAAAAcizALAAAAxyLMAgAAwLEIswAAAHCscg+zL774opKTk1WpUiV16NBBy5cvP+7yU6dO1bnnnqvo6GjVr19fI0aM0JEjR85QawEAAFCRlGuYnTNnjkaOHKkJEyZo1apVatWqlVJTU/Xzzz+HXX7mzJl66KGHNGHCBK1Zs0avv/665syZo3Hjxp3hlgMAAKAisIwxprx23qFDB7Vr105///vfJUm2bat+/fq677779NBDDxVbftiwYVqzZo0WLlwYrD3wwAP66quv9Pnnn5dqn7m5uapatapycnIUFxd3ajoC4KxgPWaVdxN+l8yEcvszBId6zHqsvJvwuzTBTDhj+ypLXvOcoTYV4/V6tXLlSo0dOzZYc7lc6t69u5YtWxZ2nYsvvlhvv/22li9frvbt2ysrK0sfffSRbr311hL3k5+fr/z8/ODvubm5kiS/3y+/3x/cr8vlkm3bsm07pD0ul0uBQEBFM39JdbfbLcuygtstWpekQCBQqrrH45ExJqRuWZbcbnexNpZUp0/0iT6VvU8RVoR8xie33HJb7mDdli2/8ctjeeQq8oZWwAQUUEARVoQsFQZhv/HLll1iPdKKDGmjz/hkZIrVvcYrS5YirIhidZdc8liFL+FGRj7jK7Fekfvk9/t/9889+lS2PlmRlozfSPbRn4syPiOZMHWvkSzJighTd0mWp0jd/LqdkupuyXIXqduS8ZujyxZ5z9sEjBT4dZ9FN1PQ9pLqFbRPfr//jD33jl3+eMotzGZnZysQCCgxMTGknpiYqLVr14Zd56abblJ2drY6d+4sY4z8fr/uuuuu455mMGnSJD32WPH/4DIyMhQTEyNJqlmzppo0aaLNmzdrz549wWXq1aunevXqaf369crJyQnWGzdurFq1amn16tXKy8sL1ps3b674+HhlZGSEDE5KSooiIyO1YsWKkDa0bdtWXq9X3377bbDmdrvVrl075eTkhDwO0dHRatWqlbKzs5WVlRWsV61aVS1atNCOHTu0ffv2YJ0+0Sf6VPY+9U7srVm7ZqlTfCd1qdYlWM88kKn07HSl1khV69jWwfqSfUu0eP9i9U7srcbRjYP19Ox0ZR7I1JC6Q5QQkRCsz9o1S1l5WRreYLgiXYUhL217mnL9uRqdPDqkT5O3TFacJ0531rszWPPaXk3eOlnJ0cnqn9Q/WM/2ZStte5pSYlPUM6FnsJ6Vl1Xh+5SRkfG7f+7Rp7L1KXl0snbN2qW8rDw1GN5ArsjCBLk9bbv8uX4lj04O6dOWyVvkifOo3p31gjXba2vr5K2KTo5WUv+kYN2X7dP2tO2KTYlVQs/C53teVp52zdql+E7xqtalWrB+IPOAstOzVSO1hmJbxwbr+5bs0/7F+5XYO1HRjaOD9ez0bB3IPKC6Q+oqIqHwH7uK3qcVK1acsedeRkaGSqvcTjPYsWOH6tatq6VLl6pjx47B+pgxY/TZZ5/pq6++KrbOokWLdOONN+qvf/2rOnTooI0bN2r48OEaOnSoHn744bD7CTczW79+ff3yyy/BaWv+86VP9Ik+SVLliZUr/CxmQf1smpk9NO7Q7/65R5/K1qeJMRMr/CymdPbNzI47NO6MPff27dunGjVqVOzTDBISEuR2u7V79+6Q+u7du5WUlBR2nYcffli33nqrbr/9dknSBRdcoEOHDumOO+7QX/7yF7lcxT/PFhUVpaioqGJ1j8cjjye0+wUDcayCB7a09WO3ezJ1y7LC1ktqY1nr9Ik+lVT/PffJZ3ySpIACCphAseX9JvzbXgXrlbbuNd5S141M2Lotu0z1ityngrH5PT/3Trb+e+2T8ZqwPxcVtm5KqNtlrAd+DarHbt5fQlt8ZaxX0D4VHffyeO6VpNyuZhAZGak2bdqEfJjLtm0tXLgwZKa2qMOHDxd74hc8aOX4OTYAAACUk3KbmZWkkSNHauDAgWrbtq3at2+vqVOn6tChQxo8eLAkacCAAapbt64mTZokSbrmmms0ZcoUXXjhhcHTDB5++GFdc801Jf4nAAAAgLNXuYbZfv36ac+ePXrkkUe0a9cutW7dWvPnzw9+KGzbtm0hM7Hjx4+XZVkaP368fvrpJ9WsWVPXXHONnnjiifLqAgAAAMpRuV5ntjxwnVkAJeE6s+WD68yirLjObPmoqNeZLfevswUAAABOFmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjlXuYfbFF19UcnKyKlWqpA4dOmj58uXHXX7//v269957Vbt2bUVFRemcc87RRx99dIZaCwAAgIrEU547nzNnjkaOHKlXXnlFHTp00NSpU5Wamqp169apVq1axZb3er3q0aOHatWqpXfffVd169bV1q1bFR8ff+YbDwAAgHJXrmF2ypQpGjp0qAYPHixJeuWVV5Senq5p06bpoYceKrb8tGnTtHfvXi1dulQRERGSpOTk5DPZZAAAAFQg5RZmvV6vVq5cqbFjxwZrLpdL3bt317Jly8KuM2/ePHXs2FH33nuv/v3vf6tmzZq66aab9OCDD8rtdoddJz8/X/n5+cHfc3NzJUl+v19+vz+4X5fLJdu2Zdt2SHtcLpcCgYCMMSesu91uWZYV3G7RuiQFAoFS1T0ej4wxIXXLsuR2u4u1saQ6faJP9KnsfYqwIuQzPrnlltsqfE2xZctv/PJYHrmKnJ0VMAEFFFCEFSFLVrDuN37ZskusR1qRIW30GZ+MTLG613hlyVKEFVGs7pJLHqvwJdzIyGd8JdYrcp/8fv/v/rlHn8rWJyvSkvEbyT76c1HGZyQTpu41kiVZEWHqLsnyFKmbX7dTUt0tWe4idVsyfnN02SIncJqAkQK/7rPoZgraXlK9gvbJ7/efsefescsfT7mF2ezsbAUCASUmJobUExMTtXbt2rDrZGVl6X//+59uvvlmffTRR9q4caPuuece+Xw+TZgwIew6kyZN0mOPPVasnpGRoZiYGElSzZo11aRJE23evFl79uwJLlOvXj3Vq1dP69evV05OTrDeuHFj1apVS6tXr1ZeXl6w3rx5c8XHxysjIyNkcFJSUhQZGakVK1aEtKFt27byer369ttvgzW326127dopJycn5HGIjo5Wq1atlJ2draysrGC9atWqatGihXbs2KHt27cH6/SJPtGnsvepd2Jvzdo1S53iO6lLtS7BeuaBTKVnpyu1Rqpax7YO1pfsW6LF+xerd2JvNY5uHKynZ6cr80CmhtQdooSIhGB91q5ZysrL0vAGwxXpKgx5advTlOvP1ejk0SF9mrxlsuI8cbqz3p3Bmtf2avLWyUqOTlb/pP7BerYvW2nb05QSm6KeCT2D9ay8rArfp4yMjN/9c48+la1PyaOTtWvWLuVl5anB8AZyRRYmyO1p2+XP9St5dHJIn7ZM3iJPnEf17qwXrNleW1snb1V0crSS+icF675sn7anbVdsSqwSehY+3/Oy8rRr1i7Fd4pXtS7VgvUDmQeUnZ6tGqk1FNs6Nljft2Sf9i/er8TeiYpuHB2sZ6dn60DmAdUdUlcRCYX/2FX0Pq1YseKMPfcyMjJUWpYpGp/PoB07dqhu3bpaunSpOnbsGKyPGTNGn332mb766qti65xzzjk6cuSINm/eHEzuU6ZM0eTJk7Vz586w+wk3M1u/fn398ssviouLk8R/vvSJPtGnoypPrFzhZzEL6mfTzOyhcYd+9889+lS2Pk2MmVjhZzGls29mdtyhcWfsubdv3z7VqFFDOTk5wbxWknKbmU1ISJDb7dbu3btD6rt371ZSUlLYdWrXrq2IiIiQUwpatGihXbt2yev1KjIystg6UVFRioqKKlb3eDzyeEK7XzAQxyrpFIaS6sdu92TqlmWFrZfUxrLW6RN9Kqn+e+6Tz/gkSQEFFDCBYsv7Tfi3vQrWK23da7ylrhuZsHVbdpnqFblPBWPze37unWz999on4zVhfy4qbN2UULfLWA/8GlSP3by/hLb4ylivoH0qOu7l8dwrSbldmisyMlJt2rTRwoULgzXbtrVw4cKQmdqiOnXqpI0bN4b8J7d+/XrVrl07bJAFAADA2a1crzM7cuRIvfbaa5o+fbrWrFmju+++W4cOHQpe3WDAgAEhHxC7++67tXfvXg0fPlzr169Xenq6Jk6cqHvvvbe8ugAAAIByVK6X5urXr5/27NmjRx55RLt27VLr1q01f/784IfCtm3bFvIWRP369fXxxx9rxIgRSklJUd26dTV8+HA9+OCD5dUFAAAAlKNy+wBYecnNzVXVqlVLdUIxgN8X6zHrxAvhlDMTfld/hnAKPGYVv0oRTr8JJvyVo06HsuS1cv86WwAAAOBkEWYBAADgWIRZAAAAOBZhFgAAAI5FmAUAAIBjEWYBAADgWIRZAAAAOBZhFgAAAI5FmAUAAIBjEWYBAADgWIRZAAAAOBZhFgAAAI5FmAUAAIBjEWYBAADgWIRZAAAAOBZhFgAAAI5FmAUAAIBjEWYBAADgWIRZAAAAOFaZw+yPP/6o7du3B39fvny57r//fr366quntGEAAADAiZQ5zN5000369NNPJUm7du1Sjx49tHz5cv3lL3/R//3f/53yBgIAAAAlKXOYXb16tdq3by9Jeuedd3T++edr6dKlmjFjht58881T3T4AAACgRGUOsz6fT1FRUZKkTz75RNdee60kqXnz5tq5c+epbR0AAABwHGUOs+edd55eeeUVLVmyRAsWLNAVV1whSdqxY4dq1KhxyhsIAAAAlKTMYfapp55SWlqaLr30UvXv31+tWrWSJM2bNy94+gEAAABwJnjKusKll16q7Oxs5ebmqlq1asH6HXfcocqVK5/SxgEAAADHc1LXmTXGaOXKlUpLS9OBAwckSZGRkYRZAAAAnFFlnpndunWrrrjiCm3btk35+fnq0aOHYmNj9dRTTyk/P1+vvPLK6WgnAAAAUEyZZ2aHDx+utm3bat++fYqOjg7W//SnP2nhwoWntHEAAADA8ZR5ZnbJkiVaunSpIiMjQ+rJycn66aefTlnDAAAAgBMp88ysbdsKBALF6tu3b1dsbOwpaRQAAABQGmUOs5dffrmmTp0a/N2yLB08eFATJkzQVVdddSrbBgAAABxXmU8zePbZZ5WamqqWLVvqyJEjuummm7RhwwYlJCRo1qxZp6ONjmdZ5d2C3ydjTvMOZjKw5eKm0z2wOOvwIlw+TvuLMHBUmcNsvXr19M0332j27Nn69ttvdfDgQd122226+eabQz4QBgAAAJxuZQ6zkuTxeHTLLbec6rYAAAAAZVLmMPvPf/7zuPcPGDDgpBsDAAAAlEWZw+zw4cNDfvf5fDp8+HDwG8AIswAAADhTynw1g3379oXcDh48qHXr1qlz5858AAwAAABnVJnDbDjNmjXTk08+WWzWFgAAADidTkmYlY5+KGzHjh2nanMAAADACZX5nNl58+aF/G6M0c6dO/X3v/9dnTp1OmUNAwAAAE6kzGG2V69eIb9blqWaNWvqj3/8o5599tlT1S4AAADghMocZm3bPh3tAAAAAMrslJ0zCwAAAJxppZqZHTlyZKk3OGXKlJNuDAAAAFAWpQqzGRkZpdqYZVm/qTEAAABAWZQqzH766aenux0AAABAmXHOLAAAAByrzFczkKQVK1bonXfe0bZt2+T1ekPu+9e//nVKGgYAAACcSJlnZmfPnq2LL75Ya9as0fvvvy+fz6fvv/9e//vf/1S1atXT0UYAAAAgrDKH2YkTJ+q5557Thx9+qMjISD3//PNau3at+vbtqwYNGpyONgIAAABhlTnMbtq0ST179pQkRUZG6tChQ7IsSyNGjNCrr756yhsIAAAAlKTMYbZatWo6cOCAJKlu3bpavXq1JGn//v06fPjwqW0dAAAAcBylDrMFofWSSy7RggULJEl9+vTR8OHDNXToUPXv31+XXXbZ6WklAAAAEEapr2aQkpKidu3aqVevXurTp48k6S9/+YsiIiK0dOlS3XDDDRo/fvxpaygAAABwrFKH2c8++0xvvPGGJk2apCeeeEI33HCDbr/9dj300EOns30AAABAiUp9mkGXLl00bdo07dy5Uy+88IK2bNmirl276pxzztFTTz2lXbt2nc52AgAAAMWU+QNgMTExGjx4sD777DOtX79effr00YsvvqgGDRro2muvPR1tBAAAAML6TV9n27RpU40bN07jx49XbGys0tPTT1W7AAAAgBM6qa+zlaTFixdr2rRpeu+99+RyudS3b1/ddtttp7JtAAAAwHGVKczu2LFDb775pt58801t3LhRF198sf72t7+pb9++iomJOV1tBAAAAMIqdZi98sor9cknnyghIUEDBgzQkCFDdO65557OtgEAAADHVeowGxERoXfffVdXX3213G736WwTAAAAUCqlDrPz5s07ne0AAAAAyuw3Xc0AAAAAKE+EWQAAADgWYRYAAACORZgFAACAYxFmAQAA4FiEWQAAADgWYRYAAACORZgFAACAYxFmAQAA4FiEWQAAADgWYRYAAACORZgFAACAYxFmAQAA4FiEWQAAADgWYRYAAACORZgFAACAYxFmAQAA4FgVIsy++OKLSk5OVqVKldShQwctX768VOvNnj1blmWpV69ep7eBAAAAqJDKPczOmTNHI0eO1IQJE7Rq1Sq1atVKqamp+vnnn4+73pYtWzRq1Ch16dLlDLUUAAAAFU25h9kpU6Zo6NChGjx4sFq2bKlXXnlFlStX1rRp00pcJxAI6Oabb9Zjjz2mxo0bn8HWAgAAoCLxlOfOvV6vVq5cqbFjxwZrLpdL3bt317Jly0pc7//+7/9Uq1Yt3XbbbVqyZMlx95Gfn6/8/Pzg77m5uZIkv98vv98f3KfL5ZJt27JtO6QtLpdLgUBAxpgT1t1utyzLCm63gGW5ZYwUGRk4pv9uWZYUEXFs3SOXy8jjKawbY8nnc8vlsuXx2MXqbrctt7uwbtsu+f0ueTy2XK7CeiDgUiDgUkREQJZV2Ha/3yXbDld3y7YtRUaG9snnq/h9su2yjZPb7f51e4FS1T2SjFwKFDmMLBm55ZMtl+ywdbdsuYN1l2y55Jctj+wi/1u6FJBLAQUUISOrSN0vl+xidbf8smTLr8jQtssnyShQrO6VZCmgiGP65K34ffp1LEs9Th6PjDEhdcuy5Ha7ix3zEVaEfMYnt9xyW4V9smXLb/zyWB65ivQpYAJHe2RFyCrSdr/xy5ZdYj3SCu2Tz/hkZIrVvcYrS5YirIhidZdc8liF42Fk5DO+EusVuU9+v79M41RSvcTXcrdbrkBAgYgIGavIc8/vl8u2i9Xdfr8s25Y/8pjnns8nGaPAsXWvV7IsBSKOOZ68XhmXSwFPkePGGLl9Ptkul+xwdbdbtrvI8WTbcvn9sj0e2a4ix1MgUPH7FAiUbZzK8DfXirRk/Eayj/5clPEZyYSpe41kSVZEmLpLsjxF6ubX7ZRUd0uWu0jdlozfHF22yDShCRgp8Os+i26moO0l1Ston/x+/ynLRif6m3vs8sdTrmE2OztbgUBAiYmJIfXExEStXbs27Dqff/65Xn/9dWVmZpZqH5MmTdJjjz1WrJ6RkaGYmBhJUs2aNdWkSRNt3rxZe/bsCS5Tr1491atXT+vXr1dOTk6w3rhxY9WqVUurV69WXl5esN68eXPFx8crIyMjZHBq1EhRbm6kRo9eEdKGyZPbKi7Oqzvv/DZY83rdmjy5nZKTc9S/f+FjkJ0drbS0VkpJyVbPnlnBelZWVc2a1UKdOu1Qly7bg/XMzJpKT2+i1NTNat26sE9LltTT4sX11Lv3ejVuXNin9PTGysyspSFDVishobBPs2Y1V1ZWvIYPzwgJrmlpFb9P2dllG6eUlBRFRkZqxYrQPrVt21Zer1ffflvYJ7fbrXaSclzJWhvRP1iPNtlq5U1TtjtFWZ6ewXpVO0stfLO0w91J2z2Fp8bUDGSqiT9dmz2p2uNuHazX8y9RvcBirY/orRxX4bsPjf3pqhXI1OrIIcqzEgr75JuleDtLGVHDQ4JrijdNkSZXK6JGh/Ypf7K8Vpy+jbyzsE/yql3+5Irfp7y8so1Tu3bKyckJeU2Jjo5Wq1atlJ2drayswude78TemrVrljrFd1KXaoV9yjyQqfTsdKXWSFXr2MI+Ldm3RIv3L1bvxN5qHF3Yp/TsdGUeyNSQukOUEFHYp1m7ZikrL0vDGwxXpKuwT2nb05Trz9Xo5NBxmrxlsuI8cbqzXuE4eW2vJm+drOToZPVPKhynbF+20ranKSU2RT0TCscpKy+rwvcpIyOjTONUtWpVtWjRQjt27ND27YWvESW+lnfqpHqLF2t9797KKfJuXuP0dNXKzNTqIUOUl1DkuTdrluKzspQxfHhIyEtJS1Nkbq5WjD7meJo8Wd64OH17Z5HjyetVu8mTlZOcrLX9ixxP2dlqlZam7JQUZfUscjxlZanFrFna0amTthc5fa5mZqaapKdrc2qq9rRuXdinJUsqfp/Wry/bOJXhb27y6GTtmrVLeVl5ajC8gVyRhQlye9p2+XP9Sh6dHNKnLZO3yBPnUb076wVrttfW1slbFZ0craT+ScG6L9un7WnbFZsSq4SehY9jXlaeds3apfhO8arWpVqwfiDzgLLTs1UjtYZiW8cG6/uW7NP+xfuV2DtR0Y2jg/Xs9GwdyDygukPqKiKh8B+Git6nFStWnLJsdKK/uRkZGSotyxSNz2fYjh07VLduXS1dulQdO3YM1seMGaPPPvtMX331VcjyBw4cUEpKil566SVdeeWVkqRBgwZp//79+uCDD8LuI9zMbP369fXLL78oLi5O0umfmY2MrPizmGfjzGxe3mmemX0nouLPYp6NM7P9j0g6PTOzlSdWrvCzmAX1s2lm9tC4Q6d3ZrZSpYo/i3k2zswePnzaZmYnxkys8LOY0tk3Mzvu0LgzNjO7b98+1ahRQzk5OcG8VpJynZlNSEiQ2+3W7t27Q+q7d+9WUlJSseU3bdqkLVu26JprrgnWCg4Ej8ejdevWqUmTJiHrREVFKSoqqti2PB6PPJ7Q7hcMxLHcRV5YSlM/drsFY+r1Fn+4jQlft22rhLpLXm/xNhYEumP5/S6FOzXa5wvf9pLq4dpSUr2i9KlgKEs7TidTt2TLI2+x+tFAF65+NNAVr/vDnsB+NIyWvh6uLSXXTdh6he/Tr3+gyzROlhW2fuwx7zNH2xBQQAFTvE9+E/5tr4L1Slv3mvDjFK5uZMLWbdllqlfkPhWMTWnHqcz1X/9Yun0lPPdKqHu8JRxP4erGhK1bth227rJtucLVfw2pxer+Eo6nitynX197yzp+pfmba7wm7M8hzQ9XNyXU7TLWA78G1WM37y+hLb4y1iton4oen781G51sPZxy/QBYZGSk2rRpo4ULFwZrtm1r4cKFITO1BZo3b67vvvtOmZmZwdu1116rbt26KTMzU/Xr1z+TzQcAAEA5K9eZWUkaOXKkBg4cqLZt26p9+/aaOnWqDh06pMGDB0uSBgwYoLp162rSpEmqVKmSzj///JD14+PjJalYHQAAAGe/cg+z/fr10549e/TII49o165dat26tebPnx/8UNi2bdvCvg0BAAAAlHuYlaRhw4Zp2LBhYe9btGjRcdd98803T32DAAAA4AhMeQIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxKkSYffHFF5WcnKxKlSqpQ4cOWr58eYnLvvbaa+rSpYuqVaumatWqqXv37sddHgAAAGevcg+zc+bM0ciRIzVhwgStWrVKrVq1Umpqqn7++eewyy9atEj9+/fXp59+qmXLlql+/fq6/PLL9dNPP53hlgMAAKC8lXuYnTJlioYOHarBgwerZcuWeuWVV1S5cmVNmzYt7PIzZszQPffco9atW6t58+b6xz/+Idu2tXDhwjPccgAAAJQ3T3nu3Ov1auXKlRo7dmyw5nK51L17dy1btqxU2zh8+LB8Pp+qV68e9v78/Hzl5+cHf8/NzZUk+f1++f3+4D5dLpds25Zt2yFtcblcCgQCMsacsO52u2VZVnC7BSzLLWOkyMjAMf13y7KkiIhj6x65XEYeT2HdGEs+n1suly2Pxy5Wd7ttud2Fddt2ye93yeOx5XIV1gMBlwIBlyIiArKswrb7/S7Zdri6W7ZtKTIytE8+X8Xvk22XbZzcbvev2wuUqu6RZORSoMhhZMnILZ9suWSHrbtlyx2su2TLJb9seWQX+d/SpYBcCiigCBlZRep+uWQXq7vllyVbfkWGtl0+SUaBYnWvJEsBRRzTJ2/F79OvY1nqcfJ4ZIwJqVuWJbfbXeyYj7Ai5DM+ueWW2yrsky1bfuOXx/LIVaRPARM42iMrQlaRtvuNX7bsEuuRVmiffMYnI1Os7jVeWbIUYUUUq7vkkscqHA8jI5/xlVivyH3y+/1lGqeS6iW+lrvdcgUCCkREyFhFnnt+v1y2Xazu9vtl2bb8kcc893w+yRgFjq17vZJlKRBxzPHk9cq4XAp4ihw3xsjt88l2uWSHq7vdst1Fjifblsvvl+3xyHYVOZ4CgYrfp0CgbONUhr+5VqQl4zeSffTnoozPSCZM3WskS7IiwtRdkuUpUje/bqekuluy3EXqtmT85uiyRaYJTcBIgV/3WXQzBW0vqV5B++T3+09ZNjrR39xjlz+ecg2z2dnZCgQCSkxMDKknJiZq7dq1pdrGgw8+qDp16qh79+5h7580aZIee+yxYvWMjAzFxMRIkmrWrKkmTZpo8+bN2rNnT3CZevXqqV69elq/fr1ycnKC9caNG6tWrVpavXq18vLygvXmzZsrPj5eGRkZIYNTo0aKcnMjNXr0ipA2TJ7cVnFxXt1557fBmtfr1uTJ7ZScnKP+/Qsfg+zsaKWltVJKSrZ69swK1rOyqmrWrBbq1GmHunTZHqxnZtZUenoTpaZuVuvWhX1asqSeFi+up96916tx48I+pac3VmZmLQ0ZsloJCYV9mjWrubKy4jV8eEZIcE1Lq/h9ys4u2zilpKQoMjJSK1aE9qlt27byer369tvCPrndbrWTlONK1tqI/sF6tMlWK2+ast0pyvL0DNar2llq4ZulHe5O2u7pEqzXDGSqiT9dmz2p2uNuHazX8y9RvcBirY/orRxX42C9sT9dtQKZWh05RHlWQmGffLMUb2cpI2p4SHBN8aYp0uRqRdTo0D7lT5bXitO3kXcW9kletcufXPH7lJdXtnFq1045OTkhrynR0dFq1aqVsrOzlZVV+Nzrndhbs3bNUqf4TupSrbBPmQcylZ6drtQaqWodW9inJfuWaPH+xeqd2FuNowv7lJ6drswDmRpSd4gSIgr7NGvXLGXlZWl4g+GKdBX2KW17mnL9uRqdHDpOk7dMVpwnTnfWKxwnr+3V5K2TlRydrP5JheOU7ctW2vY0pcSmqGdC4Thl5WVV+D5lZGSUaZyqVq2qFi1aaMeOHdq+vfA1osTX8k6dVG/xYq3v3Vs5jYs899LTVSszU6uHDFFeQpHn3qxZis/KUsbw4SEhLyUtTZG5uVox+pjjafJkeePi9O2dRY4nr1ftJk9WTnKy1vYvcjxlZ6tVWpqyU1KU1bPI8ZSVpRazZmlHp07a3qXI8ZSZqSbp6dqcmqo9rVsX9mnJkorfp/XryzZOZfibmzw6Wbtm7VJeVp4aDG8gV2Rhgtyetl3+XL+SRyeH9GnL5C3yxHlU7856wZrttbV18lZFJ0crqX9SsO7L9ml72nbFpsQqoWfh45iXladds3YpvlO8qnWpFqwfyDyg7PRs1UitodjWscH6viX7tH/xfiX2TlR04+hgPTs9WwcyD6jukLqKSCj8h6Gi92nFihWnLBud6G9uRkaGSssyRePzGbZjxw7VrVtXS5cuVceOHYP1MWPG6LPPPtNXX3113PWffPJJPf3001q0aJFSUlLCLhNuZrZ+/fr65ZdfFBcXJ+n0z8xGRlb8WcyzcWY2L+80z8y+E1HxZzHPxpnZ/kcknZ6Z2coTK1f4WcyC+tk0M3to3KHTOzNbqVLFn8U8G2dmDx8+bTOzE2MmVvhZTOnsm5kdd2jcGZuZ3bdvn2rUqKGcnJxgXitJuc7MJiQkyO12a/fu3SH13bt3KykpqYS1jnrmmWf05JNP6pNPPikxyEpSVFSUoqKiitU9Ho88ntDuFwzEsdxFXlhKUz92uwVj6vUWf7iNCV+3bauEukteb/E2FgS6Y/n9LoU7NdrnC9/2kurh2lJSvaL0qWAoSztOJ1O3ZMsjb7H60UAXrn400BWv+8OewH40jJa+Hq4tJddN2HqF79Ovf6DLNE6WFbZ+7DHvM0fbEFBAAVO8T34T/m2vgvVKW/ea8OMUrm5kwtZt2WWqV+Q+FYxNacepzPVf/1i6fSU890qoe7wlHE/h6saErVu2Hbbusm25wtV/DanF6v4SjqeK3KdfX3vLOn6l+ZtrvCbszyHND1c3JdTtMtYDvwbVYzfvL6EtvjLWK2ifih6fvzUbnWw9nHL9AFhkZKTatGkT8uGtgg9zFZ2pPdbTTz+txx9/XPPnz1fbtm3PRFMBAABQAZXrzKwkjRw5UgMHDlTbtm3Vvn17TZ06VYcOHdLgwYMlSQMGDFDdunU1adIkSdJTTz2lRx55RDNnzlRycrJ27dolSapSpYqqVKlSbv0AAADAmVfuYbZfv37as2ePHnnkEe3atUutW7fW/Pnzgx8K27ZtW8jbEC+//LK8Xq969+4dsp0JEybo0UcfPZNNBwAAQDkr9zArScOGDdOwYcPC3rdo0aKQ37ds2XL6GwQAAABHKPcvTQAAAABOFmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjkWYBQAAgGMRZgEAAOBYhFkAAAA4FmEWAAAAjlUhwuyLL76o5ORkVapUSR06dNDy5cuPu/zcuXPVvHlzVapUSRdccIE++uijM9RSAAAAVCTlHmbnzJmjkSNHasKECVq1apVatWql1NRU/fzzz2GXX7p0qfr376/bbrtNGRkZ6tWrl3r16qXVq1ef4ZYDAACgvJV7mJ0yZYqGDh2qwYMHq2XLlnrllVdUuXJlTZs2Lezyzz//vK644gqNHj1aLVq00OOPP66LLrpIf//7389wywEAAFDePOW5c6/Xq5UrV2rs2LHBmsvlUvfu3bVs2bKw6yxbtkwjR44MqaWmpuqDDz4Iu3x+fr7y8/ODv+fk5EiS9u7dK7/fH9yny+WSbduybTukLS6XS4FAQMaYE9bdbrcsywput5BbkhQREQip+nwl1T2yLCOPp7BujCW/3y3LsuXx2MXqLpctt7uwbtsuBQIuud22XK7CeiDgkm275PEEZFmFbff7XTImXN0tYyxFRIT2qeS2V5w+7d9ftnFyu92/bi9QqrrnsGRkKVDkMLJk5JZftizZYesu2b8+HyTJJVsuBWTLLbvI/5YuBeSSrYA8MrKK1P1yyRSru+WXJSO/IkLbLt/Rtpey7pGv4vfp12O41OPk8cgYE1K3LEtut7vYMe/J98hv/HLJJbdV2CdbtgImILfllqtInwImIFu2PJZHVpG2+41fRqbEeoQV2iefOToeZalbsuSxCsfDyMhv/CXWK3Kf9u7dW6ZxKql+3Ndy21bA45Gxijz3/H65jClWd/v9soyRP+KY557v1+OmlHWPzydjWQp4ihw3xsjt98u2LNnh6i6XbHeR48m25QoEZLvdsl1FjqdAoOL3ad++so9TKf/m5kfky/iNZCQrorCfkmR8R5cpU92SLE+RutHR7ZdUd0mWu0jdlkzAHK0VmSY0ASPZv26j6GYK2l5SvYL2ae/evacsG53ob+6+ffuONq/ItkpkytFPP/1kJJmlS5eG1EePHm3at28fdp2IiAgzc+bMkNqLL75oatWqFXb5CRMmmKNDxY0bN27cuHHjxs1Jtx9//PGEebJcZ2bPhLFjx4bM5Nq2rb1796pGjRqyLOs4ayI3N1f169fXjz/+qLi4uPJuDk4RxvXsw5ienRjXsw9jWnrGGB04cEB16tQ54bLlGmYTEhLkdru1e/fukPru3buVlJQUdp2kpKQyLR8VFaWoqKiQWnx8/Mk3+ncoLi6Og+4sxLiefRjTsxPjevZhTEunatWqpVquXD8AFhkZqTZt2mjhwoXBmm3bWrhwoTp27Bh2nY4dO4YsL0kLFiwocXkAAACcvcr9NIORI0dq4MCBatu2rdq3b6+pU6fq0KFDGjx4sCRpwIABqlu3riZNmiRJGj58uLp27apnn31WPXv21OzZs7VixQq9+uqr5dkNAAAAlINyD7P9+vXTnj179Mgjj2jXrl1q3bq15s+fr8TEREnStm3b5CryCc6LL75YM2fO1Pjx4zVu3Dg1a9ZMH3zwgc4///zy6sJZKyoqShMmTCh2mgacjXE9+zCmZyfG9ezDmJ4eljGlueYBAAAAUPGU+5cmAAAAACeLMAsAAADHIswCAADAsQizOC7Lskr8quDfsiycp+j4btmyRZZlKTMzs1zbBAAAYdZBBg0aJMuyZFmWIiMj1bRpU/3f//1fse87PpV27typK6+88pQvi7IpOvYRERFq1KiRxowZoyNHjpR303AKpKamyu126+uvvy52X1mO+y+//FIDBw5U06ZNVaNGDbVo0UJ33323vv/++7D7XbRokS666CJFRUWpadOmevPNN4/bzoJ/Yo69ffnllyfV74rqbB+PI0eO6N5771WNGjVUpUoV3XDDDcW+jOhYu3fv1qBBg1SnTh1VrlxZV1xxhTZs2BCyzKWXXlqsLXfddddxt3s2GTRokHr16lWqZRctWiTLsrR///5i9yUnJ2vq1KmntG1nO8Ksw1xxxRXauXOnNmzYoAceeECPPvqoJk+eXGw5r9d7SvaXlJRU6kuIlGVZlF3B2GdlZem5555TWlqaJkyYUN7Nwm+0bds2LV26VMOGDdO0adPCLnOi4962bd1333268sorlZiYqBdffFGLFy/WSy+9pCpVqqhz58568cUXQ7a5efNm9ezZU926dVNmZqbuv/9+3X777fr4449P2OZPPvlEO3fuDN7atGnz2x6ECuT3MB4jRozQhx9+qLlz5+qzzz7Tjh07dP3115e4vDFGvXr1UlZWlv79738rIyNDDRs2VPfu3XXo0KGQZYcOHRrSlqeffvqE7Qd+MwPHGDhwoLnuuutCaj169DB/+MMfgvf99a9/NbVr1zbJycnGGGO2bdtm+vTpY6pWrWqqVatmrr32WrN58+aQbbz++uumZcuWJjIy0iQlJZl77703eJ8k8/777xtjjMnPzzf33nuvSUpKMlFRUaZBgwZm4sSJYZc1xphvv/3WdOvWzVSqVMlUr17dDB061Bw4cKBYfyZPnmySkpJM9erVzT333GO8Xu+pecDOIuHG/vrrrzcXXnihMcaYQCBgJk6caJKTk02lSpVMSkqKmTt3bsjyq1evNj179jSxsbGmSpUqpnPnzmbjxo3GGGOWL19uunfvbmrUqGHi4uLMJZdcYlauXBmyftHx3bx5s5FkMjIyTkt/nahr165m2LBhZvjw4SY+Pt7UqlXLvPrqq+bgwYNm0KBBpkqVKqZJkybmo48+Clnv0UcfNTfeeKNZs2aNqVq1qjl8+HDI/cc77guMGjXKtGvXzuzcuTNs2zZu3GgaNWoU8pwYM2aMOe+880KW69evn0lNTS2xj04ad8YjvP3795uIiIiQfa9Zs8ZIMsuWLQu7zrp164wks3r16mAtEAiYmjVrmtdeey1Y69q1qxk+fHip23K2KfrcOHLkiLnvvvtMzZo1TVRUlOnUqZNZvnx5cNlPP/3USDL79u0rtp2GDRua55577sw0+izBzKzDRUdHB2dhFy5cqHXr1mnBggX6z3/+I5/Pp9TUVMXGxmrJkiX64osvVKVKFV1xxRXBdV5++WXde++9uuOOO/Tdd99p3rx5atq0adh9/e1vf9O8efP0zjvvaN26dZoxY4aSk5PDLnvo0CGlpqaqWrVq+vrrrzV37lx98sknGjZsWMhyn376qTZt2qRPP/1U06dP15tvvnnCt9YgrV69WkuXLlVkZKQkadKkSfrnP/+pV155Rd9//71GjBihW265RZ999pkk6aefftIll1yiqKgo/e9//9PKlSs1ZMiQ4FujBw4c0MCBA/X555/ryy+/VLNmzXTVVVfpwIED5dZHJ5o+fboSEhK0fPly3Xfffbr77rvVp08fXXzxxVq1apUuv/xy3XrrrTp8+LCkozNeb7zxhm655RY1b95cTZs21bvvvnvC/RQ97n/44Qe9+eab+uCDD5SUlKSXX35ZzZo1U3Jysl544QWde+65ioiI0GuvvabRo0fL/Hpp8WXLlql79+4h201NTdWyZctOuP9rr71WtWrVUufOnTVv3ryyPkxnDONR+Hb2li1bJEkrV66Uz+cL2Vfz5s3VoEGDEveVn58vSapUqVKw5nK5FBUVpc8//zxk2RkzZighIUHnn3++xo4dG3xsf2/GjBmj9957T9OnT9eqVavUtGlTpaamau/eveXdtLNT+WZplEXR//ps2zYLFiwwUVFRZtSoUWbgwIEmMTHR5OfnB5d/6623zLnnnmts2w7W8vPzTXR0tPn444+NMcbUqVPH/OUvfylxnyoyG3ffffeZP/7xjyHbK2nZV1991VSrVs0cPHgweH96erpxuVxm165dwf40bNjQ+P3+4DJ9+vQx/fr1K/2D8jsxcOBA43a7TUxMjImKijKSjMvlMu+++645cuSIqVy5slm6dGnIOrfddpvp37+/McaYsWPHmkaNGpV61jsQCJjY2Fjz4YcfBmtiZva4unbtajp37hz83e/3m5iYGHPrrbcGazt37gyZAfvvf/9ratasaXw+nzHGmOeee8507do1ZLvHO+6NMWbcuHHmgQceMMYYs3jxYlO5cmUzY8YMs3LlSnP11Vcbt9sdfDemXr16Zs2aNcYYY5o1axbyzooxR49RScVmIwvs2bPHPPvss+bLL780y5cvNw8++KCxLMv8+9//PolH7PRiPI766quvzLnnnmu2b99ujDFmxowZJjIysti22rVrZ8aMGRN2P16v1zRo0MD06dPH7N271+Tn55snn3zSSDKXX355cLm0tDQzf/588+2335q3337b1K1b1/zpT38Ku82zUcFz4+DBgyYiIsLMmDEjeJ/X6zV16tQxTz/9tDGGmdlTrdy/zhZl85///EdVqlSRz+eTbdu66aab9Oijj+ree+/VBRdcEJypk6RvvvlGGzduVGxsbMg2jhw5ok2bNunnn3/Wjh07dNlll5Vq34MGDVKPHj107rnn6oorrtDVV1+tyy+/POyya9asUatWrRQTExOsderUSbZta926dcGvKz7vvPPkdruDy9SuXVvfffddqR+P35Nu3brp5Zdf1qFDh/Tcc8/J4/Hohhtu0Pfff6/Dhw+rR48eIct7vV5deOGFkqTMzEx16dJFERERYbe9e/dujR8/XosWLdLPP/+sQCCgw4cPa9u2bae9X2eTlJSU4M9ut1s1atTQBRdcEKwVPO9//vlnSdK0adPUr18/eTxHX4r79++v0aNHa9OmTWrSpElwvZKOe0n67rvvNGjQIEnShx9+qJtvvlk33XSTJOmVV15RvXr1gtupXbu29u3bd9L9S0hI0MiRI4O/t2vXTjt27NDkyZN17bXXnvR2TxfGQ2rfvr3Wrl170vuQpIiICP3rX//SbbfdpurVq8vtdqt79+668sorgzPLknTHHXcEf77gggtUu3ZtXXbZZcUev7Pdpk2b5PP51KlTp2AtIiJC7du315o1a8qxZWcvwqzDFASayMhI1alTJ/iiKykkOErSwYMH1aZNG82YMaPYdmrWrCmXq2xnmVx00UXavHmz/t//+3/65JNP1LdvX3Xv3r1Ub8OV5NhwZVmWbNs+6e2dzWJiYoKngEybNk2tWrXS66+/rvPPP1+SlJ6errp164asU/CBvOjo6ONue+DAgfrll1/0/PPPq2HDhoqKilLHjh1P2QcJfy/CPZ+L1izLknT0A0J79+7V+++/L5/Pp5dffjm4TCAQ0LRp0/TEE08Ea8c77v1+f3B8vV5vyOtAlSpVgj8fOnRIGzZsCIaKpKSkYp9g3717t+Li4k74fCmqQ4cOWrBgQamXP5MYj+KSkpLk9Xq1f/9+xcfHh+wrKSmpxPXatGmjzMxM5eTkyOv1qmbNmurQoYPatm173LZI0saNG39XYbY04uLiJEk5OTkh4yBJ+/fvV9WqVcuhVc7FObMOUxBoGjRoEPICGs5FF12kDRs2qFatWmratGnIrWrVqoqNjVVycrIWLlxY6v3HxcWpX79+eu211zRnzhy99957Yc8BatGihb755puQT7p+8cUXcrlcOvfcc0vfYYTlcrk0btw4jR8/Xi1btlRUVJS2bdtWbJzr168v6egM1ZIlS+Tz+cJu74svvtCf//xnXXXVVTrvvPMUFRWl7OzsM9ml350ZM2aoXr16+uabb5SZmRm8Pfvss3rzzTcVCASCyx7vuG/atGnw3YzOnTtr9uzZWrt2rXw+XzCA7dmzR0OGDNF1112nWrVqSZI6duxY7NhfsGCBOnbsWKZ+ZGZmqnbt2mXuf0XzexmPNm3aKCIiImRf69at07Zt20q1r6pVq6pmzZrasGGDVqxYoeuuu+64bZF0Vjw/yqJJkyaKjIzUF198Eaz5fD59/fXXatmypSSpWbNmcrlcWrlyZci6WVlZysnJ0TnnnHNG2+x0hNmz2M0336yEhARdd911WrJkiTZv3qxFixbpz3/+s7Zv3y5JevTRR/Xss8/qb3/7mzZs2KBVq1bphRdeCLu9KVOmaNasWVq7dq3Wr1+vuXPnKikpqdh/lQX7rlSpkgYOHKjVq1fr008/1X333adbb701+NYefps+ffrI7XYrLS1No0aN0ogRIzR9+nRt2rQpOI7Tp0+XJA0bNky5ubm68cYbtWLFCm3YsEFvvfWW1q1bJ+noC+tbb72lNWvW6KuvvtLNN99cptkglN3rr7+u3r176/zzzw+53XbbbcrOztb8+fNLtZ0//elP+sc//iGfz6cbbrhB1157rVq2bKnKlStr//79qlOnjrp37666devqlVdeCa531113KSsrS2PGjNHatWv10ksv6Z133tGIESOCy/z9738POQ1p+vTpwdeAtWvXauLEiZo2bZruu+++U/fAlJOzdTyWL1+u5s2b66effpJ0NIzedtttGjlypD799FOtXLlSgwcPVseOHfWHP/whuF7z5s31/vvvB3+fO3euFi1aFLw8V48ePdSrV6/gqWabNm3S448/rpUrV2rLli2aN2+eBgwYoEsuuSTkdI/fg5iYGN19990aPXq05s+frx9++EFDhw7V4cOHddttt0mSYmNjdfvtt+uBBx7QvHnztHnzZi1evFg333yz/vCHP+jiiy8u5144C6cZnMUqV66sxYsX68EHH9T111+vAwcOqG7durrsssuCb3EMHDhQR44c0XPPPadRo0YpISFBvXv3Dru92NhYPf3009qwYYPcbrfatWunjz76KOzpCpUrV9bHH3+s4cOHq127dqpcubJuuOEGTZky5bT2+ffE4/Fo2LBhevrpp7V582bVrFlTkyZNUlZWluLj43XRRRdp3LhxkqQaNWrof//7n0aPHq2uXbvK7XardevWwXO6Xn/9dd1xxx266KKLVL9+fU2cOFGjRo0qz+6d1TZt2qRvvvlGr732WrH7qlatqssuu0yvv/66evbsecJtdevWTU2bNtXQoUP1+uuvKy0tTc8884x8Pp+qV6+unTt3qlatWiHnpktSo0aNlJ6erhEjRuj5559XvXr19I9//EOpqanBZbKzs7Vp06aQ9R5//HFt3bpVHo9HzZs315w5c0p8zXCKs3k8Dh8+rHXr1oW8K/Pcc8/J5XLphhtuUH5+vlJTU/XSSy+FbHfdunXKyckJ/r5z506NHDlSu3fvVu3atTVgwAA9/PDDwfsjIyP1ySefaOrUqTp06JDq16+vG264QePHjz/hY3Y2evLJJ2Xbtm699VYdOHBAbdu21ccff6xq1aoFl3n++ef15JNP6sEHH9TWrVuVlJSkHj166IknngieAoPSsUzRs7cBAI6zb98+XXXVVZKkv/zlL/rjH/+oypUr6+eff9aMGTP0z3/+U59//nmx8+pxejAewJnFaQYA4HDVqlXTZ599pr59++qBBx5QTEyMoqKi1KBBAy1atEivv/46wekMYjyAM4uZWQA4y+Tk5Cg3N1e1atXiK6YrAMYDOL0IswAAAHAsTjMAAACAYxFmAQAA4FiEWQAAADgWYRYAAACORZgFAACAYxFmAeAsZ1mWPvjgg/JuBgCcFoRZADgDBg0aJMuydNdddxW7795775VlWRo0aFCptrVo0SJZlqX9+/eXavmdO3fqyiuvLENrAcA5CLMAcIbUr19fs2fPVl5eXrB25MgRzZw5Uw0aNDjl+/N6vZKkpKQkLtYP4KxFmAWAM+Siiy5S/fr19a9//StY+9e//qUGDRrowgsvDNZs29akSZPUqFEjRUdHq1WrVnr33XclSVu2bFG3bt0kHf3a1KIzupdeeqmGDRum+++/XwkJCUpNTZVU/DSD7du3q3///qpevbpiYmLUtm1bffXVV5Kkb775Rt26dVNsbKzi4uLUpk0brVix4nQ+LADwm3jKuwEA8HsyZMgQvfHGG7r55pslSdOmTdPgwYO1aNGi4DKTJk3S22+/rVdeeUXNmjXT4sWLdcstt6hmzZrq3Lmz3nvvPd1www1at26d4uLiFB0dHVx3+vTpuvvuu/XFF1+E3f/BgwfVtWtX1a1bV/PmzVNSUpJWrVol27YlSTfffLMuvPBCvfzyy3K73crMzFRERMTpe0AA4DcizALAGXTLLbdo7Nix2rp1qyTpiy++0OzZs4NhNj8/XxMnTtQnn3yijh07SpIaN26szz//XGlpaeratauqV68uSapVq5bi4+NDtt+sWTM9/fTTJe5/5syZ2rNnj77++uvgdpo2bRq8f9u2bRo9erSaN28e3B4AVGSEWQA4g2rWrKmePXvqzTfflDFGPXv2VEJCQvD+jRs36vDhw+rRo0fIel6vN+RUhJK0adPmuPdnZmbqwgsvDAbZY40cOVK333673nrrLXXv3l19+vRRkyZNStEzACgfhFkAOMOGDBmiYcOGSZJefPHFkPsOHjwoSUpPT1fdunVD7ivNh7hiYmKOe3/RUxLCefTRR3XTTTcpPT1d/+///T9NmDBBs2fP1p/+9KcT7hsAygMfAAOAM+yKK66Q1+uVz+cLfkirQMuWLRUVFaVt27apadOmIbf69etLkiIjIyVJgUCgzPtOSUlRZmam9u7dW+Iy55xzjkaMGKH//ve/uv766/XGG2+UeT8AcKYQZgHgDHO73VqzZo1++OEHud3ukPtiY2M1atQojRgxQtOnT9emTZu0atUqvfDCC5o+fbokqWHDhrIsS//5z3+0Z8+e4GxuafTv319JSUnq1auXvvjiC2VlZem9997TsmXLlJeXp2HDhmnRokXaunWrvvjiC3399ddq0aLFKe0/AJxKhFkAKAdxcXGKi4sLe9/jjz+uhx9+WJMmTVKLFi10xRVXKD09XY0aNZIk1a1bV4899pgeeughJSYmBk9ZKI3IyEj997//Va1atXTVVVfpggsu0JNPPim32y23261ffvlFAwYM0DnnnKO+ffvqyiuv1GOPPXZK+gwAp4NljDHl3QgAAADgZDAzCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwLMIsAAAAHIswCwAAAMcizAIAAMCxCLMAAABwrP8P3HyZHhVURqsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Step 3: Evaluate the model on the test set\n",
        "metrics = model.val(data='Computer_Vision-1/data.yaml', split='test')  # Evaluate the test set if available\n",
        "if metrics:\n",
        "    # Access metrics from the box attribute\n",
        "    precision = metrics.box.maps[0]  # Precision for class 0\n",
        "    recall = metrics.box.maps[0]     # Recall for class 0\n",
        "    map50 = metrics.box.map50        # mAP@0.5\n",
        "    map_5095 = metrics.box.map       # mAP@0.5:0.95\n",
        "    iou = map50                      # IoU is represented as mAP@0.5\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"Model Evaluation Metrics:\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"mAP@0.5 (IoU threshold=0.5): {map50:.4f}\")\n",
        "    print(f\"mAP@0.5:0.95: {map_5095:.4f}\")\n",
        "    print(f\"Average IoU (approx as mAP@0.5): {iou:.4f}\")\n",
        "\n",
        "    # Step 4: Plot the metrics\n",
        "    metric_names = ['Precision', 'Recall', 'mAP@0.5', 'mAP@0.5:0.95', 'IoU']\n",
        "    metric_values = [precision, recall, map50, map_5095, iou]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(metric_names, metric_values, color=['blue', 'orange', 'green', 'red', 'purple'])\n",
        "    plt.ylim(0, 1)  # Metrics are between 0 and 1\n",
        "    plt.title('YOLOv8 Evaluation Metrics')\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Values')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No evaluation metrics available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AgkQGVVPJLGP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}